<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Eye Tracking</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #f0f0f0;
        }
        .container {
            display: flex;
            width: 100%;
            max-width: 1200px;
        }
        .video-container, .image-container {
            flex: 1;
            padding: 10px;
        }
        video, img {
            border: 1px solid black;
            width: 100%;
            height: auto;
        }
        canvas {
            display: none;
        }
    </style>
</head>
<body>
    <h1>Real-Time Eye Tracking</h1>
    <div class="container">
        <div class="video-container">
            <video id="video" autoplay></video>
        </div>
        <div class="image-container">
            <img id="processedImage" alt="Processed Image" />
        </div>
    </div>

    <canvas id="canvas"></canvas>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const processedImage = document.getElementById('processedImage');

        // Access the camera
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
                video.play();
                processVideo();
            })
            .catch(err => {
                console.error("Error accessing the camera: ", err);
            });

        async function processVideo() {
            // Resize the canvas to reduce the image size
            const scaleFactor = 0.5; // Adjust this factor as needed
            canvas.width = video.videoWidth * scaleFactor;
            canvas.height = video.videoHeight * scaleFactor;

            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));

            // Create a FormData object
            const formData = new FormData();
            formData.append('file', blob, 'frame.jpg');

            try {
                // Send the frame to the FastAPI server
                const response = await fetch('https://your-fastapi-url/process_frame/', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const imageBlob = await response.blob();
                const imageObjectURL = URL.createObjectURL(imageBlob);
                processedImage.src = imageObjectURL;

            } catch (err) {
                console.error("Error sending frame to server: ", err);
            }

            requestAnimationFrame(processVideo);
        }

        // Set canvas size to match video size
        video.addEventListener('loadedmetadata', () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        });
    </script>
</body>
</html>
